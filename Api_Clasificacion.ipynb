{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fab38520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://172.20.10.3:5000/ (Press CTRL+C to quit)\n",
      "172.20.10.3 - - [28/May/2023 13:21:08] \"GET / HTTP/1.1\" 200 -\n",
      "172.20.10.3 - - [28/May/2023 13:21:09] \"GET /swagger.json HTTP/1.1\" 200 -\n",
      "172.20.10.3 - - [28/May/2023 13:21:20] \"GET /predict/?plot=american%20maxwell%20smart%20works%20for%20a%20government%20spy%20agency%20in%20an%20administrative%20capacity%20.%20%20when%20the%20agency%20%27%20s%20head%20office%20is%20attacked%20%2C%20%20the%20chief%20decides%20to%20assign%20maxwell%20as%20a%20spy%20and%20partners%20him%20with%20sexy%20agent%20%20N%20%20%2C%20%20much%20to%20her%20chagrin%20.%20%20the%20duo%20nevertheless%20set%20off%20to%20combat%20their%20attackers%20by%20first%20parachuting%20off%20an%20airplane%20and%20landing%20in%20russian%20territory%20%20-%20%20followed%20closely%20by%20an%20over%20seven%20feet%20tall%20%2C%20%20%20N%20%20pound%20goon%20%2C%20%20known%20simply%20as%20dalip%20.%20%20the%20duo%20%2C%20%20handicapped%20by%20maxwell%20%27%20s%20antics%20%2C%20%20will%20eventually%20have%20their%20identities%20compromised%20%2C%20%20and%20may%20be%20chalked%20up%20as%20casualties%20%2C%20%20while%20back%20in%20america%20their%20attackers%20have%20already%20planted%20a%20bomb%20that%20is%20set%20-%20up%20to%20explode%20in%20a%20concert%20. HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, jsonify\n",
    "from flask_restx import Api, Resource, fields\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from flask_cors import CORS\n",
    "\n",
    "# Cargar los modelos y objetos necesarios\n",
    "model = pickle.load(open('modelo_clasificacion_entrenado.pkl', 'rb'))\n",
    "vect = pickle.load(open('vect.pkl', 'rb'))\n",
    "tfidf = pickle.load(open('tfidf_transformer.pkl', 'rb'))\n",
    "\n",
    "# Géneros disponibles\n",
    "cols = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family',\n",
    "        'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Romance',\n",
    "        'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War', 'Western']\n",
    "\n",
    "# Función de expansión de contracciones\n",
    "def decontracted(phrase):\n",
    "    # Específicas\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can't\", \"can not\", phrase)\n",
    "\n",
    "    # Generales\n",
    "    phrase = re.sub(r\"n't\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "\n",
    "# Crear la aplicación Flask\n",
    "app = Flask(__name__)\n",
    "CORS(app) \n",
    "#api = Api(app)\n",
    "\n",
    "api = Api(\n",
    "    app, \n",
    "    version='1.0', \n",
    "    title='Clasificación de generos de películas',\n",
    "    description='Prediction API')\n",
    "\n",
    "\n",
    "# Definir el namespace y el parser para los endpoints\n",
    "namespace = api.namespace('predict', description='Clasificación de películas')\n",
    "\n",
    "parser = api.parser()\n",
    "parser.add_argument('plot', type=str, required=True, help='Trama de la película', location='args')\n",
    "\n",
    "resource_fields = api.model('Resource', {\n",
    "    'genres': fields.List(fields.String),\n",
    "})\n",
    "\n",
    "@namespace.route('/')\n",
    "class ClasificationApi(Resource):\n",
    "\n",
    "    @api.doc(parser=parser)\n",
    "    def get(self):\n",
    "        # Obtener los parámetros de entrada\n",
    "        args = parser.parse_args()\n",
    "        plot = args['plot']\n",
    "        \n",
    "        \n",
    "        # Preprocesar los datos de entrada\n",
    "        preprocessed_plot = decontracted(plot)\n",
    "        preprocessed_plot = re.sub('[^A-Za-z]+', ' ', preprocessed_plot)\n",
    "        preprocessed_plot = ' '.join(e.lower() for e in preprocessed_plot.split() if e.lower() not in stopwords)\n",
    "        \n",
    "        # Crear el DataFrame con los datos preprocesados\n",
    "        df = pd.DataFrame({'Plot': [preprocessed_plot]})\n",
    "        \n",
    "        # Transformar los datos de entrada utilizando el vectorizador y el transformador TF-IDF\n",
    "        X_test_dtm_1 = vect.transform(df['Plot'])\n",
    "        X_test_dtm = tfidf.transform(X_test_dtm_1)\n",
    "        \n",
    "        # Realizar la predicción utilizando el modelo entrenado\n",
    "        predicted_genres = model.predict_proba(X_test_dtm)\n",
    "        \n",
    "        # Obtener los géneros basados en las columnas proporcionadas\n",
    "        movie_genres = [col for pred, col in zip(predicted_genres[0], cols) if pred >= 0.25]\n",
    "                \n",
    "        if not movie_genres:\n",
    "            movie_genres = [\"Sin Clasificación\"]\n",
    "        \n",
    "        # Devolver los géneros como una lista\n",
    "        return jsonify({'Genres': movie_genres})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False, host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8fb5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento de los datos de Entrada\n",
    "#Importación del modelo a utilizar \n",
    "model = pickle.load(open('modelo__clasificacion_entrenado.pkl', 'rb'))\n",
    "vect = pickle.load(open('vect.pkl', 'rb'))\n",
    "tfidf = pickle.load(open('tfidf_transformer.pkl', 'rb'))\n",
    "\n",
    "# Función de expansión de contracciones\n",
    "def decontracted(phrase):\n",
    "    # Específicas\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can't\", \"can not\", phrase)\n",
    "\n",
    "    # Generales\n",
    "    phrase = re.sub(r\"n't\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "\n",
    "\n",
    "# Preprocesar los datos de entrada\n",
    "preprocessed_plot = decontracted(plot)\n",
    "preprocessed_plot = re.sub('[^A-Za-z]+', ' ', preprocessed_plot)\n",
    "preprocessed_plot = ' '.join(e.lower() for e in preprocessed_plot.split() if e.lower() not in stopwords)\n",
    "        \n",
    "        # Crear el DataFrame con los datos preprocesados\n",
    "df = pd.DataFrame({'Plot': [preprocessed_plot]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2151c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = \"in the distant future the world is in the grip of another ice age .  a city originally built to house five million people is now in its death throes as the relentlessly advancing glacier is slowly crushing the metropolis ' s steel infrastructure .  the relatively few surviving fur - clad inhabitants ,  perhaps thousands ,  perhaps only hundreds ,  drift aimlessly in their grim ,  drab world ,  awaiting their inevitable fate as they try to survive from day to day with scavenged firewood and minimal diet .  their only solaces are booza ,  an alcoholic drink distilled from moss ,  and quintet ,  a seemingly innocuous board game for six players .  the only other surviving mammals are roving packs of hungry mastiffs which roam the city ' s corridors and quickly dispose of the remains of the dead .  newly arrived from the south is essex with his pregnant wife vivia ,  seeking shelter in the doomed city only to find it populated by people middle - aged or older .  they had supported themselves by hunting seals ,  but now that the last of the aquatic mammals has been killed off ,  they seek shelter in the apartment of essex ' s brother ,  a renowned quintet player .  the new arrivals quickly learn that the game has a more sinister side .\"\n",
    "\n",
    "\n",
    "preprocessed_plot = decontracted(plot)\n",
    "preprocessed_plot = re.sub('[^A-Za-z]+', ' ', preprocessed_plot)\n",
    "preprocessed_plot = ' '.join(e.lower() for e in preprocessed_plot.split() if e.lower() not in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ab5404c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distant future world grip another ice age city originally built house five million people death throes relentlessly advancing glacier slowly crushing metropolis steel infrastructure relatively surviving fur clad inhabitants perhaps thousands perhaps hundreds drift aimlessly grim drab world awaiting inevitable fate try survive day day scavenged firewood minimal diet solaces booza alcoholic drink distilled moss quintet seemingly innocuous board game six players surviving mammals roving packs hungry mastiffs roam city corridors quickly dispose remains dead newly arrived south essex pregnant wife vivia seeking shelter doomed city find populated people middle aged older supported hunting seals last aquatic mammals killed seek shelter apartment essex brother renowned quintet player new arrivals quickly learn game sinister side'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5a98383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento de los datos de Entrada\n",
    "#Importación del modelo a utilizar \n",
    "model = pickle.load(open('modelo__clasificacion_entrenado.pkl', 'rb'))\n",
    "vect = pickle.load(open('vect.pkl', 'rb'))\n",
    "tfidf = pickle.load(open('tfidf_transformer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "47e596f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Crear el DataFrame con los datos preprocesados\n",
    "df = pd.DataFrame({'Plot': [preprocessed_plot]})\n",
    "        \n",
    "        # Transformar los datos de entrada utilizando el vectorizador y el transformador TF-IDF\n",
    "X_test_dtm_1 = vect.transform(df['Plot'])\n",
    "X_test_dtm = tfidf.transform(X_test_dtm_1)\n",
    "        \n",
    "        # Realizar la predicción utilizando el modelo entrenado\n",
    "predicted_genres = model.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f1fc6c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13220793 0.10337998 0.03000895 0.03553452 0.16020853 0.10902483\n",
      "  0.05605391 0.64903071 0.0579415  0.06861865 0.01861578 0.03170106\n",
      "  0.11811061 0.02944152 0.02343625 0.28558367 0.00083139 0.09073283\n",
      "  0.34142068 0.01198829 0.03094736 0.22478141 0.034449   0.02263806]]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ebe33736",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "97edaee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres = [col for pred, col in zip(predicted_genres[0], cols) if pred >= 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27388667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p_Drama', 'p_Mystery', 'p_Sci-Fi']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef0cef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = np.argmax(movie_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ad5c272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c22f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
